"""
This module generates the features from the images. The features have been generated by first detecting 68 landmarks on
the face and then calculating the angles between these landmark points and the mean of these landmark points.
"""
import numpy as np
import cv2
import dlib
import glob
import math


# Generate the features and the corresponding labels.
def build_features(files, label, training_file, labels_file):
    for file in files:
        img = cv2.imread(file)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        xlist = []
        ylist = []

        detections = detector(gray, 1)

        for k, d in enumerate(detections):
            shape = predictor(gray, d)
            for i in xrange(1, 68):
                xlist.append(float(shape.part(i).x))
                ylist.append(float(shape.part(i).y))

            xmean = np.mean(xlist)
            ymean = np.mean(ylist)

            if xlist[26] == xlist[29]:
                anglenose = 0
            else:
                anglenose = int(math.atan((ylist[26] - ylist[29]) / (xlist[26] - xlist[29])) * (180 / math.pi))

            if anglenose < 0:
                anglenose += 90
            else:
                anglenose -= 90

            for i in xrange(0, len(xlist)):
                if xlist[i] == xmean:
                    angle = 90 - anglenose
                else:
                    angle = int(math.atan((ylist[i] - ymean) / (xlist[i] - xmean)) * (180 / math.pi)) - anglenose
                angle = str(angle)
                training_file.write(angle + " ")

            training_file.write("\n")
            labels_file.write(label + "\n")


# Build the features for training data and test data.
def build_data(emotion, label):
    files = glob.glob('dataset/%s/*' % emotion)
    np.random.shuffle(files)
    training_data = []
    cross_validation_data = []
    training_data_length = int(0.8 * len(files))
    for i in xrange(0, training_data_length):
        training_data.append(files[i])
    for i in xrange(training_data_length + 1, len(files)):
        cross_validation_data.append(files[i])

    build_features(training_data, str(label), training_features, training_labels)
    build_features(cross_validation_data, str(label), validation_features, validation_labels)


if __name__ == '__main__':

    # Only 5 emotions have been used, since there were very less examples for the remaining emotions.
    emotions = ['disgust', 'surprise', 'neutral', 'happy', 'anger']
    np.random.shuffle(emotions)

    # Ordering for the emotions.
    labels = dict()
    labels['disgust'] = 1
    labels['surprise'] = 2
    labels['neutral'] = 3
    labels['happy'] = 4
    labels['anger'] = 5

    # Files to store the features.
    training_features = open('TrainingFeatures.txt', 'w')
    validation_features = open('ValidationFeatures.txt', 'w')
    training_labels = open('TrainingLabels.txt', 'w')
    validation_labels = open('ValidationLabels.txt', 'w')

    # Used for detecting landmarks on the face.
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

    # Build training and testing data for each emotion.
    for emotion in emotions:
        build_data(emotion, labels[emotion])

    training_features.close()
    validation_features.close()
    training_labels.close()
    validation_labels.close()
